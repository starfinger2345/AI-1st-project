{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7b0516e-1b1a-4313-8151-766ef55b1f40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\programdata\\anaconda3\\envs\\myenv\\lib\\site-packages (4.12.0.88)\n",
      "Requirement already satisfied: mediapipe in c:\\programdata\\anaconda3\\envs\\myenv\\lib\\site-packages (0.10.14)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\envs\\myenv\\lib\\site-packages (2.0.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\programdata\\anaconda3\\envs\\myenv\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: Pillow in c:\\programdata\\anaconda3\\envs\\myenv\\lib\\site-packages (11.3.0)\n",
      "Requirement already satisfied: PyQt5 in c:\\programdata\\anaconda3\\envs\\myenv\\lib\\site-packages (5.15.11)\n",
      "Requirement already satisfied: absl-py in c:\\programdata\\anaconda3\\envs\\myenv\\lib\\site-packages (from mediapipe) (2.3.1)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\programdata\\anaconda3\\envs\\myenv\\lib\\site-packages (from mediapipe) (25.3.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\programdata\\anaconda3\\envs\\myenv\\lib\\site-packages (from mediapipe) (25.9.23)\n",
      "Requirement already satisfied: jax in c:\\programdata\\anaconda3\\envs\\myenv\\lib\\site-packages (from mediapipe) (0.4.30)\n",
      "Requirement already satisfied: jaxlib in c:\\programdata\\anaconda3\\envs\\myenv\\lib\\site-packages (from mediapipe) (0.4.30)\n",
      "Requirement already satisfied: matplotlib in c:\\programdata\\anaconda3\\envs\\myenv\\lib\\site-packages (from mediapipe) (3.9.4)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\programdata\\anaconda3\\envs\\myenv\\lib\\site-packages (from mediapipe) (4.12.0.88)\n",
      "Requirement already satisfied: protobuf<5,>=4.25.3 in c:\\programdata\\anaconda3\\envs\\myenv\\lib\\site-packages (from mediapipe) (4.25.8)\n",
      "Requirement already satisfied: sounddevice>=0.4.4 in c:\\programdata\\anaconda3\\envs\\myenv\\lib\\site-packages (from mediapipe) (0.5.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\programdata\\anaconda3\\envs\\myenv\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\programdata\\anaconda3\\envs\\myenv\\lib\\site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\programdata\\anaconda3\\envs\\myenv\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: PyQt5-sip<13,>=12.15 in c:\\programdata\\anaconda3\\envs\\myenv\\lib\\site-packages (from PyQt5) (12.17.0)\n",
      "Requirement already satisfied: PyQt5-Qt5<5.16.0,>=5.15.2 in c:\\programdata\\anaconda3\\envs\\myenv\\lib\\site-packages (from PyQt5) (5.15.2)\n",
      "Requirement already satisfied: CFFI>=1.0 in c:\\programdata\\anaconda3\\envs\\myenv\\lib\\site-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
      "Requirement already satisfied: pycparser in c:\\programdata\\anaconda3\\envs\\myenv\\lib\\site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
      "Requirement already satisfied: ml-dtypes>=0.2.0 in c:\\programdata\\anaconda3\\envs\\myenv\\lib\\site-packages (from jax->mediapipe) (0.5.3)\n",
      "Requirement already satisfied: opt-einsum in c:\\programdata\\anaconda3\\envs\\myenv\\lib\\site-packages (from jax->mediapipe) (3.4.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.6 in c:\\programdata\\anaconda3\\envs\\myenv\\lib\\site-packages (from jax->mediapipe) (8.7.0)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\programdata\\anaconda3\\envs\\myenv\\lib\\site-packages (from importlib-metadata>=4.6->jax->mediapipe) (3.23.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\programdata\\anaconda3\\envs\\myenv\\lib\\site-packages (from matplotlib->mediapipe) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\envs\\myenv\\lib\\site-packages (from matplotlib->mediapipe) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\programdata\\anaconda3\\envs\\myenv\\lib\\site-packages (from matplotlib->mediapipe) (4.59.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\programdata\\anaconda3\\envs\\myenv\\lib\\site-packages (from matplotlib->mediapipe) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\envs\\myenv\\lib\\site-packages (from matplotlib->mediapipe) (25.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\programdata\\anaconda3\\envs\\myenv\\lib\\site-packages (from matplotlib->mediapipe) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\programdata\\anaconda3\\envs\\myenv\\lib\\site-packages (from matplotlib->mediapipe) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\programdata\\anaconda3\\envs\\myenv\\lib\\site-packages (from matplotlib->mediapipe) (6.5.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\envs\\myenv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python mediapipe numpy scikit-learn Pillow PyQt5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0211cfe-c7a8-473b-81a4-c49be7580de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "from PIL import ImageFont, ImageDraw, Image\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from collections import deque\n",
    "import time\n",
    "\n",
    "# PyQt5 관련 모듈\n",
    "from PyQt5.QtWidgets import QApplication, QWidget, QLabel, QHBoxLayout, QVBoxLayout, QTextEdit\n",
    "from PyQt5.QtGui import QImage, QPixmap\n",
    "from PyQt5.QtCore import QThread, pyqtSignal, Qt\n",
    "\n",
    "# 키보드 제어 라이브러리\n",
    "import pyautogui\n",
    "import pyperclip\n",
    "\n",
    "# ======================= PART 01. 수어 인식 모델 및 데이터 처리 로직 =======================\n",
    "\n",
    "# >> 상수 및 설정 <<\n",
    "consonant_labels = ['ㄱ', 'ㄴ', 'ㄷ', 'ㄹ', 'ㅁ', 'ㅂ', 'ㅅ', 'ㅇ', 'ㅈ', 'ㅊ', 'ㅋ', 'ㅌ', 'ㅍ', 'ㅎ']\n",
    "vowel_labels = ['ㅏ', 'ㅐ', 'ㅑ', 'ㅒ', 'ㅓ', 'ㅔ', 'ㅕ', 'ㅖ', 'ㅗ', 'ㅛ', 'ㅜ', 'ㅠ', 'ㅡ','ㅣ','ㅚ','ㅟ','ㅢ']\n",
    "command_labels = ['shift', 'space', 'end']\n",
    "labels = consonant_labels + vowel_labels + command_labels\n",
    "\n",
    "font_path = \"C:/Windows/Fonts/gulim.ttc\"\n",
    "dataset_file = 'member_hands.csv'\n",
    "\n",
    "first_spelling = ['ㄱ', 'ㄲ', 'ㄴ', 'ㄷ', 'ㄸ', 'ㄹ', 'ㅁ', 'ㅂ', 'ㅃ', 'ㅅ', 'ㅆ', 'ㅇ', 'ㅈ', 'ㅉ', 'ㅊ', 'ㅋ', 'ㅌ', 'ㅍ', 'ㅎ']\n",
    "second_spelling = ['ㅏ', 'ㅐ', 'ㅑ', 'ㅒ', 'ㅓ', 'ㅔ', 'ㅕ', 'ㅖ', 'ㅗ', 'ㅘ', 'ㅙ', 'ㅚ', 'ㅛ', 'ㅜ', 'ㅝ', 'ㅞ', 'ㅟ', 'ㅠ', 'ㅡ', 'ㅢ', 'ㅣ']\n",
    "last_spelling = [' ', 'ㄱ', 'ㄲ', 'ㄳ', 'ㄴ', 'ㄵ', 'ㄶ', 'ㄷ', 'ㄹ', 'ㄺ', 'ㄻ', 'ㄼ', 'ㄽ', 'ㄾ', 'ㄿ', 'ㅀ', 'ㅁ', 'ㅂ', 'ㅄ', 'ㅅ', 'ㅆ', 'ㅇ', 'ㅈ', 'ㅊ', 'ㅋ', 'ㅌ', 'ㅍ', 'ㅎ']\n",
    "\n",
    "start_kr = 44032\n",
    "end_kr = 55203\n",
    "\n",
    "def is_hangul(char):\n",
    "    return start_kr <= ord(char) <= end_kr\n",
    "\n",
    "def decompose(char):\n",
    "    if not is_hangul(char): return None, None, None\n",
    "    code = ord(char) - start_kr\n",
    "    last_index = code % 28\n",
    "    code //= 28\n",
    "    second_index = code % 21\n",
    "    first_index = code // 21\n",
    "    return first_spelling[first_index], second_spelling[second_index], last_spelling[last_index]\n",
    "\n",
    "def compose(first, second, last=' '):\n",
    "    try:\n",
    "        first_index = first_spelling.index(first)\n",
    "        second_index = second_spelling.index(second)\n",
    "        last_index = last_spelling.index(last)\n",
    "        code = start_kr + (first_index * 588) + (second_index * 28) + last_index\n",
    "        return chr(code)\n",
    "    except (ValueError, IndexError):\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "class HangulAssembler:\n",
    "    def __init__(self):\n",
    "        self.full_text = \"\"\n",
    "        self.command_shift = False\n",
    "\n",
    "        # 각 조합 규칙에 대한 매핑 테이블\n",
    "        self.double_consonant_map = {'ㄱ': 'ㄲ', 'ㄷ': 'ㄸ', 'ㅂ': 'ㅃ', 'ㅅ': 'ㅆ', 'ㅈ': 'ㅉ'}\n",
    "        self.complex_last_map = {('ㄱ', 'ㅅ'): 'ㄳ', ('ㄴ', 'ㅈ'): 'ㄵ', ('ㄴ', 'ㅎ'): 'ㄶ', ('ㄹ', 'ㄱ'): 'ㄺ', ('ㄹ', 'ㅁ'): 'ㄻ', ('ㄹ', 'ㅂ'): 'ㄼ', ('ㄹ', 'ㅅ'): 'ㄽ', ('ㄹ', 'ㅌ'): 'ㄾ', ('ㄹ', 'ㅍ'): 'ㄿ', ('ㄹ', 'ㅎ'): 'ㅀ', ('ㅂ', 'ㅅ'): 'ㅄ'}\n",
    "        self.dipthong_map = {('ㅗ', 'ㅏ'): 'ㅘ', ('ㅗ', 'ㅐ'): 'ㅙ', ('ㅗ', 'ㅣ'): 'ㅚ', ('ㅜ', 'ㅓ'): 'ㅝ', ('ㅜ', 'ㅔ'): 'ㅞ', ('ㅜ', 'ㅣ'): 'ㅟ', ('ㅡ', 'ㅣ'): 'ㅢ'}\n",
    "        \n",
    "        # 연음 법칙을 위한 겹받침 분해 맵\n",
    "        self.last_decompose_map = {v: k for k, v in self.complex_last_map.items()}\n",
    "\n",
    "    def add_char(self, char):\n",
    "        \"\"\"인식된 글자(자음/모음/명령어)를 받아 전체 텍스트를 업데이트.\"\"\"\n",
    "        if char in command_labels:\n",
    "            self._process_command(char)\n",
    "        elif char in consonant_labels or char in self.double_consonant_map.values(): # 쌍자음도 처리\n",
    "            self._process_consonant(char)\n",
    "        elif char in vowel_labels:\n",
    "            self._process_vowel(char)\n",
    "        \n",
    "        return self.full_text\n",
    "\n",
    "    def _process_command(self, char):\n",
    "        if char == 'shift':\n",
    "            self.command_shift = True\n",
    "        elif char == 'space':\n",
    "            self.full_text += \" \"\n",
    "        elif char == 'end':\n",
    "            self.full_text += \".\\n\"\n",
    "\n",
    "    def _process_consonant(self, char):\n",
    "        # 1. 쌍자음 처리\n",
    "        if self.command_shift and char in self.double_consonant_map:\n",
    "            char = self.double_consonant_map[char]\n",
    "        self.command_shift = False\n",
    "\n",
    "        last_char = self.full_text[-1] if self.full_text else None\n",
    "        \n",
    "        # 2. 받침(종성) 추가 또는 겹받침 처리\n",
    "        if last_char and is_hangul(last_char):\n",
    "            first, second, last = decompose(last_char)\n",
    "            # 2-1. 기존에 받침이 없는 경우 -> 새 받침 추가\n",
    "            if last == ' ' and char in last_spelling:\n",
    "                composed_char = compose(first, second, char)\n",
    "                if composed_char: self.full_text = self.full_text[:-1] + composed_char\n",
    "                return\n",
    "            # 2-2. 기존에 받침이 있는 경우 -> 겹받침 시도\n",
    "            elif last in last_spelling and (last, char) in self.complex_last_map:\n",
    "                complex_last = self.complex_last_map[(last, char)]\n",
    "                composed_char = compose(first, second, complex_last)\n",
    "                if composed_char: self.full_text = self.full_text[:-1] + composed_char\n",
    "                return\n",
    "        \n",
    "        # [수정 1] 겹받침 등 모든 조합에 실패했을 경우, 새 글자로 추가 \n",
    "        self.full_text += char\n",
    "\n",
    "    def _process_vowel(self, char):\n",
    "        self.command_shift = False\n",
    "        last_char = self.full_text[-1] if self.full_text else None\n",
    "\n",
    "        if not last_char:\n",
    "            # 모음으로 시작할 경우 'ㅇ'을 초성으로 추가\n",
    "            composed_char = compose('ㅇ', char)\n",
    "            if composed_char: self.full_text += composed_char\n",
    "            else: self.full_text += char # 조합 실패 시 모음만 추가\n",
    "            return\n",
    "\n",
    "        # [수정 2] 1. 마지막 글자가 자음인 경우 -> 자음+모음 조합\n",
    "        # last_spelling 대신 first_spelling을 사용하여 모든 쌍자음(ㄸ, ㅃ, ㅉ)을 처리\n",
    "        if last_char in first_spelling:\n",
    "            composed_char = compose(last_char, char)\n",
    "            if composed_char: self.full_text = self.full_text[:-1] + composed_char\n",
    "            return\n",
    "\n",
    "        if is_hangul(last_char):\n",
    "            first, second, last = decompose(last_char)\n",
    "            # 2. 연음 법칙 처리 (받침이 있는 경우)\n",
    "            if last != ' ':\n",
    "                # 2-1. 겹받침인 경우 -> 분리 후 연음\n",
    "                if last in self.last_decompose_map:\n",
    "                    last_1, last_2 = self.last_decompose_map[last]\n",
    "                    syllable_1 = compose(first, second, last_1)\n",
    "                    syllable_2 = compose(last_2, char)\n",
    "                    if syllable_1 and syllable_2: self.full_text = self.full_text[:-1] + syllable_1 + syllable_2\n",
    "                # 2-2. 홑받침인 경우 -> 받침을 다음 글자 초성으로\n",
    "                else:\n",
    "                    syllable_1 = compose(first, second) # 받침 없는 글자\n",
    "                    syllable_2 = compose(last, char) # 받침이 초성이 된 새 글자\n",
    "                    if syllable_1 and syllable_2: self.full_text = self.full_text[:-1] + syllable_1 + syllable_2\n",
    "                return\n",
    "            # 3. 이중모음 처리 (받침이 없는 경우)\n",
    "            else:\n",
    "                if (second, char) in self.dipthong_map:\n",
    "                    diphthong = self.dipthong_map[(second, char)]\n",
    "                    composed_char = compose(first, diphthong)\n",
    "                    if composed_char: self.full_text = self.full_text[:-1] + composed_char\n",
    "                    return\n",
    "        \n",
    "        # 4. 위 조건에 해당 없으면 새 글자로 추가 (모음으로 시작하는 것과 동일하게 처리)\n",
    "        composed_char = compose('ㅇ', char)\n",
    "        if composed_char: self.full_text += composed_char\n",
    "        else: self.full_text += char\n",
    "\n",
    "\n",
    "# >> mediapipe Hands 모델 로드 및 초기화 <<\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# >> 특징 추출 유틸리티 함수들 <<\n",
    "def putText_korean(image, text, pos, font_path, font_size, color):\n",
    "    img_pil = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    draw = ImageDraw.Draw(img_pil)\n",
    "    font = ImageFont.truetype(font_path, font_size)\n",
    "    draw.text(pos, text, font=font, fill=tuple(color[::-1]))\n",
    "    return cv2.cvtColor(np.array(img_pil), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "def calculate_angles(joint):\n",
    "    v1 = joint[[0,1,2,3,0,5,6,7,0,9,10,11,0,13,14,15,0,17,18,19],:]\n",
    "    v2 = joint[[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20],:]\n",
    "    v = v2 - v1\n",
    "    v = v / np.linalg.norm(v, axis=1)[:, np.newaxis]\n",
    "    angle = np.arccos(np.einsum('nt,nt->n',\n",
    "        v[[0,1,2,4,5,6,8,9,10,12,13,14,16,17,18],:],\n",
    "        v[[1,2,3,5,6,7,9,10,11,13,14,15,17,18,19],:]))\n",
    "    angle = np.degrees(angle)\n",
    "    return angle.astype(np.float32)\n",
    "\n",
    "def calculate_distances(joint):\n",
    "    thumb_tip = joint[4]\n",
    "    other_tips = joint[[8, 12, 16, 20]]\n",
    "    distances = np.linalg.norm(other_tips - thumb_tip, axis=1)\n",
    "    return distances.astype(np.float32)\n",
    "\n",
    "def calculate_orientation_vectors(joint):\n",
    "    v_direction = joint[9] - joint[0]\n",
    "    if np.linalg.norm(v_direction) == 0: v_direction = np.zeros(3)\n",
    "    else: v_direction = v_direction / np.linalg.norm(v_direction)\n",
    "\n",
    "    v1 = joint[5] - joint[0]\n",
    "    v2 = joint[17] - joint[0]\n",
    "    v_normal = np.cross(v1, v2)\n",
    "    if np.linalg.norm(v_normal) == 0: v_normal = np.zeros(3)\n",
    "    else: v_normal = v_normal / np.linalg.norm(v_normal)\n",
    "\n",
    "    return np.concatenate([v_direction, v_normal]).astype(np.float32)\n",
    "\n",
    "# >> 데이터 로드 및 전처리 <<\n",
    "def load_and_preprocess(dataset_file):\n",
    "    print(\"데이터셋 로드 및 전처리 시작...\")\n",
    "    try:\n",
    "        labels_str = np.genfromtxt(dataset_file, delimiter=',', skip_header=1, usecols=0, encoding=\"EUC-KR\", dtype=str)\n",
    "        landmarks_data = np.genfromtxt(dataset_file, delimiter=',', skip_header=1, usecols=range(1, 127), encoding=\"EUC-KR\").astype(np.float32)\n",
    "    except Exception as e:\n",
    "        print(f\"데이터 파일 로드 오류: {e}\")\n",
    "        return None, None, None\n",
    "\n",
    "    all_features = []\n",
    "    for row in landmarks_data:\n",
    "        lh_landmarks = row[:63].reshape(21, 3); rh_landmarks = row[63:].reshape(21, 3)\n",
    "\n",
    "        lh_angles = calculate_angles(lh_landmarks) if np.any(lh_landmarks) else np.zeros(15, dtype=np.float32)\n",
    "        rh_angles = calculate_angles(rh_landmarks) if np.any(rh_landmarks) else np.zeros(15, dtype=np.float32)\n",
    "        lh_coords = (lh_landmarks[1:] - lh_landmarks[0]).flatten() if np.any(lh_landmarks) else np.zeros(60, dtype=np.float32)\n",
    "        rh_coords = (rh_landmarks[1:] - rh_landmarks[0]).flatten() if np.any(rh_landmarks) else np.zeros(60, dtype=np.float32)\n",
    "        lh_distances = calculate_distances(lh_landmarks) if np.any(lh_landmarks) else np.zeros(4, dtype=np.float32)\n",
    "        rh_distances = calculate_distances(rh_landmarks) if np.any(rh_landmarks) else np.zeros(4, dtype=np.float32)\n",
    "        lh_orientation = calculate_orientation_vectors(lh_landmarks) if np.any(lh_landmarks) else np.zeros(6, dtype=np.float32)\n",
    "        rh_orientation = calculate_orientation_vectors(rh_landmarks) if np.any(rh_landmarks) else np.zeros(6, dtype=np.float32)\n",
    "\n",
    "        features = np.concatenate([lh_angles, rh_angles, lh_coords, rh_coords, lh_distances, rh_distances, lh_orientation, rh_orientation])\n",
    "        all_features.append(features)\n",
    "\n",
    "    all_features = np.array(all_features, dtype=np.float32)\n",
    "    encoder = LabelEncoder()\n",
    "    encoded_labels = encoder.fit_transform(labels_str)\n",
    "\n",
    "    print(\"데이터 전처리 완료!\")\n",
    "    return all_features, encoded_labels, encoder\n",
    "\n",
    "# >> 모델 학습 <<\n",
    "def train_model(dataset_file):\n",
    "    X, y, encoder = load_and_preprocess(dataset_file)\n",
    "    if X is None: return None, None\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "    print(\"--- 랜덤 포레스트 모델 학습 시작 ---\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(\"\\n--- 학습 완료 ---\")\n",
    "    print(f\"데이터 특징 차원: {X.shape[1]}\")\n",
    "    print(f\"모델 테스트 정확도: {accuracy * 100:.2f}%\")\n",
    "    return model, encoder\n",
    "\n",
    "# ======================= PART 02. PyQt5 GUI 및 영상 처리 스레드 =======================\n",
    "\n",
    "class VideoThread(QThread):\n",
    "    change_pixmap_signal = pyqtSignal(np.ndarray)\n",
    "    update_text_signal = pyqtSignal(str)\n",
    "\n",
    "    def __init__(self, model, encoder):\n",
    "        super().__init__()\n",
    "        self._run_flag = True\n",
    "        self.model = model\n",
    "        self.encoder = encoder\n",
    "        \n",
    "        # [수정 1] 새로운 변수 추가\n",
    "        self.last_recognition_time = 0  # 마지막으로 제스처를 인식한 시간\n",
    "        self.RECOGNITION_COOLDOWN = 1.5 # 인식 후 쿨타임 (1.5초). 이 값을 조절하여 인식 속도 변경 가능\n",
    "\n",
    "    def run(self):\n",
    "        history = deque(maxlen=5)\n",
    "        display_label = \"\"\n",
    "        display_start_time = None\n",
    "        display_duration = 1.5 # 쿨타임과 비슷하게 조정\n",
    "\n",
    "        cap = cv2.VideoCapture(0)\n",
    "        with mp_hands.Hands(max_num_hands=2, min_detection_confidence=0.5, min_tracking_confidence=0.5) as hands:\n",
    "            while self._run_flag and cap.isOpened():\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    continue\n",
    "\n",
    "                frame = cv2.flip(frame, 1)\n",
    "                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                result = hands.process(frame_rgb)\n",
    "                guide_text = \"손을 보여주세요\"\n",
    "                current_time = time.time() # 현재 시간 측정\n",
    "\n",
    "                if result.multi_hand_landmarks:\n",
    "                    # ... (특징 추출 부분은 기존과 동일) ...\n",
    "                    init_zeros = {'angles': np.zeros(15), 'coords': np.zeros(60), 'distances': np.zeros(4), 'orientation': np.zeros(6)}\n",
    "                    lh_features, rh_features = init_zeros.copy(), init_zeros.copy()\n",
    "\n",
    "                    for i, hand_landmarks in enumerate(result.multi_hand_landmarks):\n",
    "                        handedness = result.multi_handedness[i].classification[0].label\n",
    "                        joint = np.array([[lm.x, lm.y, lm.z] for lm in hand_landmarks.landmark])\n",
    "                        features = {\n",
    "                            'angles': calculate_angles(joint), 'coords': (joint[1:] - joint[0]).flatten(),\n",
    "                            'distances': calculate_distances(joint), 'orientation': calculate_orientation_vectors(joint)\n",
    "                        }\n",
    "                        if handedness == \"Left\": lh_features = features\n",
    "                        elif handedness == \"Right\": rh_features = features\n",
    "                        mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "                    feature_vector = np.concatenate([\n",
    "                        lh_features['angles'], rh_features['angles'], lh_features['coords'], rh_features['coords'],\n",
    "                        lh_features['distances'], rh_features['distances'], lh_features['orientation'], rh_features['orientation']\n",
    "                    ]).reshape(1, -1)\n",
    "\n",
    "                    predicted_index = self.model.predict(feature_vector)\n",
    "                    predicted_label = self.encoder.inverse_transform(predicted_index)[0]\n",
    "                    history.append(predicted_label)\n",
    "\n",
    "                    # [수정 2] 제스처 인식 및 전달 로직 변경\n",
    "                    if len(history) == 5 and len(set(history)) == 1:\n",
    "                        # 쿨타임이 지났는지 확인\n",
    "                        if current_time - self.last_recognition_time > self.RECOGNITION_COOLDOWN:\n",
    "                            recognized_gesture = history[-1]\n",
    "                            print(f\"Recognized: {recognized_gesture} at {current_time:.2f}\")\n",
    "\n",
    "                            # GUI에 신호 전달\n",
    "                            self.update_text_signal.emit(recognized_gesture)\n",
    "\n",
    "                            # 화면 표시용 변수 업데이트 및 쿨타임 타이머 초기화\n",
    "                            display_label = recognized_gesture\n",
    "                            display_start_time = current_time\n",
    "                            self.last_recognition_time = current_time # 마지막 인식 시간 업데이트\n",
    "                            history.clear()\n",
    "\n",
    "                if display_start_time and ((current_time - display_start_time) < display_duration):\n",
    "                    display_text = display_label\n",
    "                else:\n",
    "                    display_text = guide_text\n",
    "\n",
    "                frame = putText_korean(frame, display_text, (50, 420), font_path, 40, (0, 255, 0))\n",
    "                self.change_pixmap_signal.emit(frame)\n",
    "\n",
    "        cap.release()\n",
    "\n",
    "    def stop(self):\n",
    "        self._run_flag = False\n",
    "        self.wait()\n",
    "\n",
    "class HandGestureApp(QWidget):\n",
    "    def __init__(self, model, encoder):\n",
    "        super().__init__()\n",
    "        self.setWindowTitle(\"수어 번역 프로그램 ('q'를 눌러 종료)\")\n",
    "        self.display_width = 640\n",
    "        self.display_height = 480\n",
    "\n",
    "        # UI 요소 생성\n",
    "        self.image_label = QLabel(self)\n",
    "        self.image_label.resize(self.display_width, self.display_height)\n",
    "        self.image_label.setStyleSheet(\"border: 2px solid black;\")\n",
    "\n",
    "        self.chat_box = QTextEdit(self)\n",
    "        self.chat_box.setReadOnly(True)\n",
    "        self.chat_box.setFixedWidth(200) # ⭐ 대화창 너비 고정\n",
    "        self.chat_box.setStyleSheet(\"font-size: 20px; border: 2px solid black;\")\n",
    "\n",
    "        # ⭐ 수평 레이아웃으로 변경\n",
    "        hbox = QHBoxLayout()\n",
    "        hbox.addWidget(self.image_label)\n",
    "        hbox.addWidget(self.chat_box)\n",
    "        self.setLayout(hbox)\n",
    "\n",
    "        # HangulAssembler 인스턴스 생성\n",
    "        self.assembler = HangulAssembler()\n",
    "\n",
    "        # 비디오 스레드 생성 및 시작\n",
    "        self.thread = VideoThread(model, encoder)\n",
    "        self.thread.change_pixmap_signal.connect(self.update_image)\n",
    "        self.thread.update_text_signal.connect(self.update_chat)\n",
    "        self.thread.start()\n",
    "\n",
    "    def update_image(self, cv_img):\n",
    "        qt_img = self.convert_cv_qt(cv_img)\n",
    "        self.image_label.setPixmap(qt_img)\n",
    "\n",
    "    def update_chat(self, new_char):\n",
    "        # assembler에 새 글자 추가하고, 반환된 전체 텍스트로 화면을 업데이트\n",
    "        full_text = self.assembler.add_char(new_char)\n",
    "        self.chat_box.setText(full_text)\n",
    "        self.chat_box.verticalScrollBar().setValue(self.chat_box.verticalScrollBar().maximum()) # 자동 스크롤\n",
    "\n",
    "        \n",
    "\n",
    "    def convert_cv_qt(self, cv_img):\n",
    "        rgb_image = cv2.cvtColor(cv_img, cv2.COLOR_BGR2RGB)\n",
    "        h, w, ch = rgb_image.shape\n",
    "        bytes_per_line = ch * w\n",
    "        convert_to_Qt_format = QImage(rgb_image.data, w, h, bytes_per_line, QImage.Format_RGB888)\n",
    "        p = convert_to_Qt_format.scaled(self.display_width, self.display_height, Qt.KeepAspectRatio)\n",
    "        return QPixmap.fromImage(p)\n",
    "\n",
    "    # 'q' 키를 누르면 종료 (이벤트 핸들러)\n",
    "    def keyPressEvent(self, event):\n",
    "        if event.key() == Qt.Key_Q:\n",
    "            self.close()\n",
    "\n",
    "    def closeEvent(self, event):\n",
    "        self.thread.stop()\n",
    "        event.accept()\n",
    "\n",
    "# ======================= PART 03. 메인 실행 부분 =======================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 1. 모델 학습\n",
    "    trained_model, label_encoder = train_model(dataset_file)\n",
    "    \n",
    "    # 2. 모델 학습 성공 시 GUI 앱 실행\n",
    "    if trained_model and label_encoder:\n",
    "        app = QApplication(sys.argv)\n",
    "        window = HandGestureApp(trained_model, label_encoder)\n",
    "        window.show()\n",
    "        sys.exit(app.exec_())\n",
    "    else:\n",
    "        print(\"모델 학습에 실패하여 프로그램을 종료합니다.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
