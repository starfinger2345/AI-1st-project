{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7897c44b-7eb9-4fa2-be7c-284650765609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'sign_language_model.joblib'에서 모델을 성공적으로 불러왔습니다.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'encoder'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 200\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sl_model:\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;66;03m# 2. GUI 앱 실행, 로드된 모델 객체 전달\u001b[39;00m\n\u001b[0;32m    199\u001b[0m     app \u001b[38;5;241m=\u001b[39m QApplication(sys\u001b[38;5;241m.\u001b[39margv)\n\u001b[1;32m--> 200\u001b[0m     window \u001b[38;5;241m=\u001b[39m \u001b[43mHandGestureApp\u001b[49m\u001b[43m(\u001b[49m\u001b[43msl_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    201\u001b[0m     window\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m    202\u001b[0m     sys\u001b[38;5;241m.\u001b[39mexit(app\u001b[38;5;241m.\u001b[39mexec_())\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'encoder'"
     ]
    }
   ],
   "source": [
    "# ======================= 실행 전 라이브러리 로드 & 설정 =======================\n",
    "import sys\n",
    "import os\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import time\n",
    "\n",
    "# PyQt5 관련 모듈\n",
    "from PyQt5.QtWidgets import QApplication, QWidget, QLabel, QHBoxLayout, QTextEdit\n",
    "from PyQt5.QtGui import QImage, QPixmap\n",
    "from PyQt5.QtCore import QThread, pyqtSignal, Qt\n",
    "\n",
    "# MediaPipe Hands 모델 로드\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# ---직접 만든 모듈에서 클래스와 함수 로드---\n",
    "from manage_model import SignLanguageModel, FeatureExtractor\n",
    "from hangul_processor import HangulAssembler\n",
    "from config import font_path, rec_cool_time, history_maxlen, display_duration\n",
    "# model_utils.py의 putText_korean 함수는 여전히 필요\n",
    "from hangul_processor import putText_korean\n",
    "\n",
    "\n",
    "# ======================= PyQt5 GUI 및 영상 처리 스레드 =======================\n",
    "\n",
    "class VideoThread(QThread):\n",
    "    change_pixmap_signal = pyqtSignal(np.ndarray)\n",
    "    update_text_signal = pyqtSignal(str)\n",
    "\n",
    "    def __init__(self, sl_model_instance): # SignLanguageModel 객체를 통째로 수신\n",
    "        super().__init__()\n",
    "        self._run_flag = True\n",
    "        self.sl_model = sl_model_instance # 모델 객체 저장\n",
    "        \n",
    "        self.last_rec_time = 0\n",
    "        \n",
    "        self.cap = cv2.VideoCapture(0)\n",
    "\n",
    "    def run(self):\n",
    "        history = deque(maxlen=history_maxlen)\n",
    "        entered_string = []\n",
    "        display_label = ''\n",
    "        display_start_time = None\n",
    "\n",
    "        with mp_hands.Hands(max_num_hands=2, min_detection_confidence=0.5, min_tracking_confidence=0.5) as hands:\n",
    "            while self._run_flag and self.cap.isOpened():\n",
    "                ret, frame = self.cap.read()\n",
    "                if not ret: # 카메라가 강제 종료되면 ret이 False가 되어 루프 탈출\n",
    "                    break\n",
    "\n",
    "                frame = cv2.flip(frame, 1)\n",
    "                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                result = hands.process(frame_rgb)\n",
    "                guide_text = \"손을 보여주세요\"\n",
    "                current_time = time.time()\n",
    "\n",
    "\n",
    "                if result.multi_hand_landmarks:\n",
    "                    init_zeros = {'angles': np.zeros(15), 'coords': np.zeros(60), 'distances': np.zeros(4), 'orientation': np.zeros(6)}\n",
    "                    lh_features, rh_features = init_zeros.copy(), init_zeros.copy()\n",
    "                    \n",
    "                    for i, hand_landmarks in enumerate(result.multi_hand_landmarks):\n",
    "                        handedness = result.multi_handedness[i].classification[0].label\n",
    "                        joint = np.array([[lm.x, lm.y, lm.z] for lm in hand_landmarks.landmark])\n",
    "\n",
    "                        features = {\n",
    "                            'angles': calculate_angles(joint),\n",
    "                            'coords': (joint[1:] - joint[0]).flatten(),\n",
    "                            'distances': calculate_distances(joint),\n",
    "                            'orientation': calculate_orientation_vectors(joint)\n",
    "                        }\n",
    "\n",
    "                        if handedness == \"Left\": lh_features = features\n",
    "                        elif handedness == \"Right\": rh_features = features\n",
    "                        mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "\n",
    "                    # 정보를 1차원 배열로 변환\n",
    "                    feature_vector = np.concatenate([\n",
    "                        lh_features['angles'], rh_features['angles'],\n",
    "                        lh_features['coords'], rh_features['coords'],\n",
    "                        lh_features['distances'], rh_features['distances'],\n",
    "                        lh_features['orientation'], rh_features['orientation']\n",
    "                    ]).reshape(1, -1)\n",
    "                    \n",
    "                    # SignLanguageModel 객체로 예측 수행\n",
    "                    predicted_index = self.sl_model.predict(feature_vector)\n",
    "                    predicted_label = self.encoder.inverse_transform(predicted_index)[0]\n",
    "                    \n",
    "                    history.append(predicted_label)\n",
    "\n",
    "                    if len(history) == 5 and len(set(history)) == 1:\n",
    "                        # 레이블 인식 및 쿨타임 타이머 작동\n",
    "                        if current_time - self.last_rec_time > self.rec_cool_time:\n",
    "                            mapped_label = history[-1]\n",
    "                            # 사람이 인식할 수 있는 시간으로 변경\n",
    "                            readable_time = time.strftime(\"%H시 %M분 %S초\", time.localtime(current_time))\n",
    "                            print(f\"인식!!: {mapped_label} ({readable_time})\")\n",
    "\n",
    "                            # 인식한 레이블 -> GUI에 전달\n",
    "                            self.update_text_signal.emit(mapped_label)\n",
    "\n",
    "                            # 화면 표시용 변수 업데이터 & 쿨타임 타이머 초기화\n",
    "                            display_label = mapped_label\n",
    "                            display_start_time = current_time\n",
    "                            self.last_rec_time = current_time  # 마지막 인식 시간 업데이트\n",
    "                            history.clear()\n",
    "\n",
    "                if display_start_time and ((current_time - display_start_time) < display_duration):\n",
    "                    display_text = display_label\n",
    "                else:\n",
    "                    display_text = guide_text\n",
    "\n",
    "                frame = putText_korean(frame, display_text, (50, 420), font_path, 40, (0, 255, 0))\n",
    "                self.change_pixmap_signal.emit(frame)\n",
    "        self.cap.release()\n",
    "\n",
    "    def stop(self):\n",
    "        self._run_flag = False\n",
    "        if self.cap.isOpened(): # 카메라를 강제로 해제 >> cap.read() 대기 상태를 중단\n",
    "            self.cap.release()\n",
    "        self.wait() # 스레드가 완전히 종료될 때까지 대기\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class HandGestureApp(QWidget):\n",
    "    def __init__(self, model, encoder):\n",
    "        super().__init__()\n",
    "        self.setWindowTitle(\"수어 번역 프로그램 ('q'를 눌러 종료)\")\n",
    "        self.display_width = 640\n",
    "        self.display_height = 480\n",
    "\n",
    "        # UI 요소 생성\n",
    "        self.image_label = QLabel(self)\n",
    "        self.image_label.resize(self.display_width, self.display_height)\n",
    "        self.image_label.setStyleSheet(\"border: 2px solid black;\")\n",
    "\n",
    "        self.chat_box = QTextEdit(self)\n",
    "        self.chat_box.setReadOnly(True)\n",
    "        self.chat_box.setFixedWidth(200) # 대화창 너비 고정\n",
    "        self.chat_box.setStyleSheet(\"font-size: 20px; border: 2px solid black;\")\n",
    "\n",
    "        # 수평 레이아웃으로 변경\n",
    "        hbox = QHBoxLayout()\n",
    "        hbox.addWidget(self.image_label)\n",
    "        hbox.addWidget(self.chat_box)\n",
    "        self.setLayout(hbox)\n",
    "\n",
    "        # HangulAssembler 인스턴스 생성\n",
    "        self.assembler = HangulAssembler()\n",
    "\n",
    "        # 비디오 스레드 생성 및 시작\n",
    "        self.thread = VideoThread(sl_model)\n",
    "        self.thread.change_pixmap_signal.connect(self.update_image)\n",
    "        self.thread.update_text_signal.connect(self.update_chat)\n",
    "        self.thread.start()\n",
    "\n",
    "    def update_image(self, cv_img):\n",
    "        qt_img = self.convert_cv_qt(cv_img)\n",
    "        self.image_label.setPixmap(qt_img)\n",
    "\n",
    "    def update_chat(self, new_char):\n",
    "        # assembler에 새 글자 추가하고, 반환된 전체 텍스트로 화면을 업데이트\n",
    "        full_text = self.assembler.add_char(new_char)\n",
    "        self.chat_box.setText(full_text)\n",
    "        self.chat_box.verticalScrollBar().setValue(self.chat_box.verticalScrollBar().maximum()) # 자동 스크롤\n",
    "\n",
    "    def convert_cv_qt(self, cv_img):\n",
    "        rgb_image = cv2.cvtColor(cv_img, cv2.COLOR_BGR2RGB)\n",
    "        h, w, ch = rgb_image.shape\n",
    "        bytes_per_line = ch * w\n",
    "        convert_to_Qt_format = QImage(rgb_image.data, w, h, bytes_per_line, QImage.Format_RGB888)\n",
    "        p = convert_to_Qt_format.scaled(self.display_width, self.display_height, Qt.KeepAspectRatio)\n",
    "        return QPixmap.fromImage(p)\n",
    "\n",
    "    # 'q' 키를 누르면 종료 (이벤트 핸들러)\n",
    "    def keyPressEvent(self, event):\n",
    "        if event.key() == Qt.Key_Q:\n",
    "            self.close()\n",
    "        \n",
    "\n",
    "    def closeEvent(self, event):\n",
    "        self.thread.stop()\n",
    "        event.accept()\n",
    "        cv2.destroyAllWindows()\n",
    "        cv2.waitKey(1)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 1. SignLanguageModel 클래스를 사용해 저장된 모델 로드\n",
    "    sl_model = SignLanguageModel.load()\n",
    "    \n",
    "    if sl_model:\n",
    "        # 2. GUI 앱 실행, 로드된 모델 객체 전달\n",
    "        app = QApplication(sys.argv)\n",
    "        window = HandGestureApp(sl_model)\n",
    "        window.show()\n",
    "        sys.exit(app.exec_())\n",
    "    else:\n",
    "        print(\"모델 로드에 실패하여 프로그램을 종료합니다.\")\n",
    "        print(\"먼저 train.py를 실행하여 모델을 학습하고 저장해주세요.\")\n",
    "        sys.exit()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
